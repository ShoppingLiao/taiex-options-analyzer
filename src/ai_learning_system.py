"""
AI å­¸ç¿’ç³»çµ±
ç´¯ç©ä¸¦å­¸ç¿’æ­·å²åˆ†æè¨˜éŒ„ï¼ŒæŒçºŒæ”¹é€²åˆ†æå“è³ª
"""

import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional
from dataclasses import dataclass, asdict


@dataclass
class AnalysisRecord:
    """åˆ†æè¨˜éŒ„"""
    date: str  # YYYYMMDD
    close_price: float
    pc_ratio: float
    sentiment: str
    trend_signal: str  # 'bullish', 'bearish', 'neutral'
    
    # AI åˆ†æå…§å®¹
    market_observation: str
    position_strategy: str
    risk_assessment: str
    trading_plan: str
    
    # å¾ŒçºŒé©—è­‰ï¼ˆå¯é¸ï¼‰
    next_day_price: Optional[float] = None
    prediction_accuracy: Optional[str] = None  # 'correct', 'partially_correct', 'incorrect'
    lessons_learned: Optional[str] = None


class AILearningSystem:
    """AI å­¸ç¿’ç³»çµ± - å¾æ­·å²åˆ†æä¸­å­¸ç¿’ä¸¦æ”¹é€²"""
    
    def __init__(self, data_dir: str = 'data/ai_learning'):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)

        self.records_file = self.data_dir / 'analysis_records.json'
        self.insights_file = self.data_dir / 'learned_insights.json'
        self.reference_dir = self.data_dir / 'reference_analysis'
        self.reference_dir.mkdir(parents=True, exist_ok=True)

        self.records: List[AnalysisRecord] = []
        self.insights: Dict = {}
        self.reference_analyses: List[Dict] = []

        self._load_data()
        self._load_reference_analyses()
    
    def _load_data(self):
        """è¼‰å…¥æ­·å²è³‡æ–™"""
        # è¼‰å…¥åˆ†æè¨˜éŒ„
        if self.records_file.exists():
            with open(self.records_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.records = [AnalysisRecord(**record) for record in data]
        
        # è¼‰å…¥å­¸ç¿’æ´å¯Ÿ
        if self.insights_file.exists():
            with open(self.insights_file, 'r', encoding='utf-8') as f:
                self.insights = json.load(f)

    def _load_reference_analyses(self):
        """è¼‰å…¥åƒè€ƒåˆ†æè³‡æ–™ï¼ˆå¤–éƒ¨å°ˆå®¶åˆ†æï¼‰"""
        self.reference_analyses = []
        for json_file in self.reference_dir.glob('*.json'):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    data['_filename'] = json_file.name
                    self.reference_analyses.append(data)
            except Exception as e:
                print(f"è¼‰å…¥åƒè€ƒåˆ†æå¤±æ•—: {json_file.name} - {e}")

        # æŒ‰æ—¥æœŸæ’åº
        self.reference_analyses.sort(
            key=lambda x: x.get('target_settlement_date', ''),
            reverse=True
        )

    def get_reference_methodology(self) -> Dict:
        """ç²å–åƒè€ƒåˆ†ææ–¹æ³•è«–"""
        if not self.reference_analyses:
            return {}

        # å½™æ•´æ‰€æœ‰åƒè€ƒåˆ†æçš„æ–¹æ³•è«–
        all_steps = []
        all_factors = []

        for ref in self.reference_analyses:
            methodology = ref.get('analysis_methodology', {})
            steps = methodology.get('steps', [])
            factors = methodology.get('key_factors', [])

            for step in steps:
                if step not in all_steps:
                    all_steps.append(step)

            for factor in factors:
                if factor not in all_factors:
                    all_factors.append(factor)

        return {
            'analysis_steps': all_steps,
            'key_factors': all_factors,
            'reference_count': len(self.reference_analyses)
        }

    def get_reference_for_settlement(self, settlement_type: str = None) -> List[Dict]:
        """ç²å–çµç®—æ—¥ç›¸é—œçš„åƒè€ƒåˆ†æ"""
        results = []
        for ref in self.reference_analyses:
            if settlement_type:
                if settlement_type.lower() in ref.get('settlement_type', '').lower():
                    results.append(ref)
            else:
                results.append(ref)
        return results

    def get_settlement_analysis_template(self) -> Dict:
        """å¾åƒè€ƒåˆ†æä¸­æå–çµç®—åˆ†ææ¨¡æ¿"""
        if not self.reference_analyses:
            return {}

        # ä½¿ç”¨æœ€æ–°çš„åƒè€ƒåˆ†æä½œç‚ºæ¨¡æ¿
        latest = self.reference_analyses[0] if self.reference_analyses else {}

        return {
            'analysis_dimensions': [
                'market_data',           # å¸‚å ´ç¾æ³æ•¸æ“š
                'pc_ratio_analysis',     # P/C Ratio åˆ†æ
                'oi_analysis',           # æœªå¹³å€‰é‡åˆ†æ
                'iv_analysis',           # éš±å«æ³¢å‹•ç‡åˆ†æ
                'settlement_prediction', # çµç®—é æ¸¬
                'observation_points'     # è§€å¯Ÿé‡é»
            ],
            'oi_analysis_structure': {
                'resistance_zone': 'å£“åŠ›å€åˆ†æï¼ˆCall OI ç‰†ï¼‰',
                'support_zone': 'æ”¯æ’å€åˆ†æï¼ˆPut OI ç‰†ï¼‰',
                'key_changes': 'é‡è¦å±¥ç´„åƒ¹çš„ OI è®ŠåŒ–'
            },
            'prediction_structure': {
                'initial_range': 'åˆæ­¥é æ¸¬å€é–“',
                'revised_range': 'ä¿®æ­£å¾Œå€é–“ï¼ˆè€ƒæ…® IV ç­‰å› ç´ ï¼‰',
                'optimal_settlement_for_mm': 'èŠå®¶æœ€ä½³æ”¶å‰²å€é–“',
                'scenarios': 'å¤šç©ºæƒ…å¢ƒåˆ†æ'
            },
            'reference_source': latest.get('source', 'Unknown')
        }

    def _save_data(self):
        """å„²å­˜è³‡æ–™"""
        # å„²å­˜åˆ†æè¨˜éŒ„
        with open(self.records_file, 'w', encoding='utf-8') as f:
            json.dump([asdict(r) for r in self.records], f, ensure_ascii=False, indent=2)
        
        # å„²å­˜å­¸ç¿’æ´å¯Ÿ
        with open(self.insights_file, 'w', encoding='utf-8') as f:
            json.dump(self.insights, f, ensure_ascii=False, indent=2)
    
    def add_record(self, record: AnalysisRecord):
        """æ–°å¢åˆ†æè¨˜éŒ„"""
        self.records.append(record)
        self._save_data()
        self._update_insights()
    
    def _update_insights(self):
        """æ›´æ–°å­¸ç¿’æ´å¯Ÿ"""
        if len(self.records) < 5:
            return  # è‡³å°‘éœ€è¦ 5 ç­†è¨˜éŒ„æ‰èƒ½é–‹å§‹å­¸ç¿’
        
        # åˆ†æ PC Ratio èˆ‡å¸‚å ´èµ°å‹¢çš„é—œä¿‚
        self._analyze_pc_ratio_patterns()
        
        # åˆ†ææˆåŠŸé æ¸¬çš„å…±åŒç‰¹å¾µ
        self._analyze_successful_predictions()
        
        # åˆ†æä¸åŒå¸‚å ´æƒ…å¢ƒçš„è¡¨ç¾
        self._analyze_market_scenarios()
        
        self._save_data()
    
    def _analyze_pc_ratio_patterns(self):
        """åˆ†æ PC Ratio æ¨¡å¼"""
        patterns = {
            'extremely_low': [],  # < 0.7
            'low': [],            # 0.7 - 0.9
            'neutral': [],        # 0.9 - 1.1
            'high': [],           # 1.1 - 1.3
            'extremely_high': []  # > 1.3
        }
        
        for record in self.records:
            if record.next_day_price is None:
                continue
            
            price_change = record.next_day_price - record.close_price
            change_pct = (price_change / record.close_price) * 100
            
            pc = record.pc_ratio
            if pc < 0.7:
                patterns['extremely_low'].append(change_pct)
            elif pc < 0.9:
                patterns['low'].append(change_pct)
            elif pc < 1.1:
                patterns['neutral'].append(change_pct)
            elif pc < 1.3:
                patterns['high'].append(change_pct)
            else:
                patterns['extremely_high'].append(change_pct)
        
        # è¨ˆç®—å¹³å‡è®ŠåŒ–
        self.insights['pc_ratio_patterns'] = {}
        for level, changes in patterns.items():
            if changes:
                avg_change = sum(changes) / len(changes)
                self.insights['pc_ratio_patterns'][level] = {
                    'avg_change_pct': round(avg_change, 2),
                    'sample_size': len(changes),
                    'interpretation': self._interpret_pc_pattern(level, avg_change)
                }
    
    def _interpret_pc_pattern(self, level: str, avg_change: float) -> str:
        """è§£è®€ PC Ratio æ¨¡å¼"""
        if level == 'extremely_low':
            if avg_change > 0:
                return "æ¥µä½ PC Ratio é€šå¸¸ä¼´éš¨ä¸Šæ¼²ï¼Œå¸‚å ´éåº¦æ¨‚è§€éœ€è­¦æƒ•åè½‰"
            else:
                return "æ¥µä½ PC Ratio åè€Œä¸‹è·Œï¼Œå¯èƒ½æ˜¯å¤šé ­é™·é˜±"
        elif level == 'extremely_high':
            if avg_change < 0:
                return "æ¥µé«˜ PC Ratio é€šå¸¸ä¼´éš¨ä¸‹è·Œï¼Œå¸‚å ´éåº¦æ‚²è§€éœ€æ³¨æ„åå½ˆ"
            else:
                return "æ¥µé«˜ PC Ratio åè€Œä¸Šæ¼²ï¼Œå¯èƒ½æ˜¯ç©ºé ­é™·é˜±"
        return "ä¸­æ€§å€é–“ï¼Œéœ€æ­é…å…¶ä»–æŒ‡æ¨™åˆ¤æ–·"
    
    def _analyze_successful_predictions(self):
        """åˆ†ææˆåŠŸé æ¸¬çš„å…±åŒç‰¹å¾µ"""
        successful = [r for r in self.records if r.prediction_accuracy == 'correct']
        
        if len(successful) >= 3:
            self.insights['success_factors'] = {
                'total_predictions': len([r for r in self.records if r.prediction_accuracy]),
                'successful_count': len(successful),
                'success_rate': round(len(successful) / len([r for r in self.records if r.prediction_accuracy]) * 100, 1),
                'common_traits': self._extract_common_traits(successful)
            }
    
    def _extract_common_traits(self, records: List[AnalysisRecord]) -> List[str]:
        """æå–æˆåŠŸé æ¸¬çš„å…±åŒç‰¹å¾µ"""
        traits = []
        
        # åˆ†ææƒ…ç·’åˆ†å¸ƒ
        sentiments = [r.sentiment for r in records]
        if sentiments.count('neutral') / len(sentiments) > 0.5:
            traits.append("ä¸­æ€§å¸‚å ´è¼ƒå®¹æ˜“é æ¸¬")
        
        # åˆ†æè¶¨å‹¢ä¿¡è™Ÿ
        trends = [r.trend_signal for r in records]
        if len(set(trends)) == 1:
            traits.append(f"å–®ä¸€æ–¹å‘è¶¨å‹¢ ({trends[0]}) è¼ƒç‚ºæ˜ç¢º")
        
        return traits
    
    def _analyze_market_scenarios(self):
        """åˆ†æä¸åŒå¸‚å ´æƒ…å¢ƒ"""
        scenarios = {}
        
        for record in self.records:
            key = f"{record.sentiment}_{record.trend_signal}"
            if key not in scenarios:
                scenarios[key] = {
                    'count': 0,
                    'successful': 0,
                    'observations': []
                }
            
            scenarios[key]['count'] += 1
            if record.prediction_accuracy == 'correct':
                scenarios[key]['successful'] += 1
            
            if record.lessons_learned:
                scenarios[key]['observations'].append(record.lessons_learned)
        
        self.insights['market_scenarios'] = scenarios
    
    def get_historical_context(self, current_pc_ratio: float, current_sentiment: str) -> Dict:
        """ç²å–æ­·å²èƒŒæ™¯è³‡è¨Šï¼Œå¹«åŠ©ç•¶å‰åˆ†æ"""
        context = {
            'similar_situations': [],
            'learned_insights': [],
            'risk_warnings': []
        }
        
        # å°‹æ‰¾ç›¸ä¼¼æƒ…æ³
        for record in self.records[-20:]:  # æœ€è¿‘ 20 ç­†
            if abs(record.pc_ratio - current_pc_ratio) < 0.1:
                context['similar_situations'].append({
                    'date': record.date,
                    'pc_ratio': record.pc_ratio,
                    'outcome': record.prediction_accuracy or 'æœªé©—è­‰',
                    'lesson': record.lessons_learned or 'ç„¡'
                })
        
        # åŠ å…¥å­¸ç¿’æ´å¯Ÿ
        if 'pc_ratio_patterns' in self.insights:
            for level, data in self.insights['pc_ratio_patterns'].items():
                if self._is_pc_in_range(current_pc_ratio, level):
                    context['learned_insights'].append(data['interpretation'])
        
        # é¢¨éšªè­¦å‘Š
        if current_sentiment in ['extremely_bullish', 'extremely_bearish']:
            context['risk_warnings'].append("æ¥µç«¯æƒ…ç·’å¯èƒ½å°è‡´åè½‰ï¼Œéœ€è¬¹æ…")
        
        return context
    
    def _is_pc_in_range(self, pc_ratio: float, level: str) -> bool:
        """åˆ¤æ–· PC Ratio æ˜¯å¦åœ¨ç‰¹å®šç¯„åœ"""
        if level == 'extremely_low':
            return pc_ratio < 0.7
        elif level == 'low':
            return 0.7 <= pc_ratio < 0.9
        elif level == 'neutral':
            return 0.9 <= pc_ratio < 1.1
        elif level == 'high':
            return 1.1 <= pc_ratio < 1.3
        elif level == 'extremely_high':
            return pc_ratio >= 1.3
        return False
    
    def generate_learning_summary(self) -> str:
        """ç”Ÿæˆå­¸ç¿’æ‘˜è¦"""
        summary_parts = []

        # åˆ†æè¨˜éŒ„çµ±è¨ˆ
        if len(self.records) >= 5:
            summary_parts.append(f"ğŸ“š å·²ç´¯ç© {len(self.records)} ç­†åˆ†æè¨˜éŒ„")

            if 'success_factors' in self.insights:
                sf = self.insights['success_factors']
                summary_parts.append(f"ğŸ¯ é æ¸¬æˆåŠŸç‡: {sf['success_rate']}% ({sf['successful_count']}/{sf['total_predictions']})")

            if 'pc_ratio_patterns' in self.insights:
                summary_parts.append(f"ğŸ“Š å·²å»ºç«‹ {len(self.insights['pc_ratio_patterns'])} ç¨® PC Ratio æ¨¡å¼åˆ†æ")
        else:
            summary_parts.append(f"ğŸ“š åˆ†æè¨˜éŒ„: {len(self.records)} ç­†ï¼ˆæŒçºŒç´¯ç©ä¸­ï¼‰")

        # åƒè€ƒåˆ†æçµ±è¨ˆ
        if self.reference_analyses:
            summary_parts.append(f"ğŸ“– åƒè€ƒåˆ†æ: {len(self.reference_analyses)} ä»½å¤–éƒ¨å°ˆå®¶åˆ†æ")
            methodology = self.get_reference_methodology()
            if methodology.get('key_factors'):
                summary_parts.append(f"ğŸ” å·²å­¸ç¿’ {len(methodology['key_factors'])} å€‹é—œéµåˆ†æå› å­")

        return "\n".join(summary_parts)
    
    def get_experience_level(self) -> tuple[str, str]:
        """ç²å–ç¶“é©—ç­‰ç´š"""
        count = len(self.records)
        
        if count < 10:
            return "æ–°æ‰‹", "ğŸŒ±"
        elif count < 30:
            return "å­¸ç¿’ä¸­", "ğŸ“ˆ"
        elif count < 50:
            return "é€²éš", "ğŸ“"
        elif count < 100:
            return "å°ˆå®¶", "â­"
        else:
            return "å¤§å¸«", "ğŸ‘‘"
